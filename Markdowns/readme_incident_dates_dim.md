# ğŸ“… Spark ETL â€“Â Kreiranje `Incident_datesDIM` dimenzijske tablice

## ğŸ¯ Cilj

Dimenzija **Incident\_datesDIM** opisuje trajanje FEMA incidenta:

| Stupac                | Opis                                                       |
| --------------------- | ---------------------------------------------------------- |
| `incident_dates_tk`   | Surrogate kljuÄ (1Â â€¦Â n)                                    |
| `version`             | SCD verzija (trenutno 1)                                   |
| `date_from`           | Datum kada red postaje aktivan                             |
| `date_to`             | Datum kraja (NULLÂ = joÅ¡ aktivan)                           |
| `incident_begin_date` | PoÄetni datum incidenta                                    |
| `incident_end_date`   | ZavrÅ¡ni datum incidenta                                    |
| `incident_duration`   | Trajanje u satima (ako nedostaje â€‘ izraÄuna se fallbackom) |

> **Prirodni kljuÄ**: (`incident_begin_date`, `incident_end_date`)
>
> Dodajemo i **UNKNOWN red** (`incident_dates_tk = 0`) za nepovezane Äinjenice.

---

## ğŸ—‚ï¸ Arhitektura koda

### 1.â€¯Unicode izlaz

```python
sys.stdout.reconfigure(encoding="utf-8")
```

OmoguÄ‡ava prikaz hrvatskih znakova u Windows/VSÂ Code terminalu.

---

### 2.â€¯Spark helper

```python
def get_spark_session():
    return (SparkSession.builder
            .appName("US_DISASTER_SCHEMA")
            .config("spark.sql.shuffle.partitions", "4")
            .getOrCreate())
```

- PokreÄ‡e Spark aplikaciju s malim brojem shuffleâ€‘particija (4) â€‘ dovoljno za \~60â€¯k redova.

---

### 3.â€¯Transform funkcija `transform_incident_dates_dim()`

#### 3.1 Extract iz baze (80â€¯%)

```python
spark.read.jdbc(... '"Disaster"' ...)
    .select(to_date(col("incident_begin_date")).alias("incident_begin_date"),
            to_date(col("incident_end_date")).alias("incident_end_date"),
            col("incident_duration").cast("int"))
```

- `` â€“ skida vremensku zonu / vrijeme â†’ Äisti samo datum.
- `incident_duration` se pretvara u `int` (sati).

#### 3.2 Extract iz CSVâ€‘a (20â€¯%)

Ista schema, isti `select`. Time je `unionByName` trivijalan.

#### 3.3 Union + dedup

```python
all_dates = (db.unionByName(csv)
             .dropna(subset=["incident_begin_date", "incident_end_date"])
             .withColumn("incident_duration", coalesce(
                     col("incident_duration"),                  # ako postoji
                     datediff(col("incident_end_date"),         # inaÄe izraÄunaj
                              col("incident_begin_date")) * 24
             ).cast("int"))
             .dropDuplicates(["incident_begin_date", "incident_end_date"]))
```

- `coalesce` â‡’ ako je trajanje NULL â†’ izraÄunaj razliku dana Ã—Â 24Â =Â sati.
- `dropDuplicates` jamÄi **jedan red po (begin, end)**.

#### 3.4 Surrogate kljuÄ + SCD

```python
w = Window.orderBy("incident_begin_date", "incident_end_date")
dim = (all_dates
       .withColumn("incident_dates_tk", row_number().over(w))
       .withColumn("version", lit(1))
       .withColumn("date_from", current_timestamp())
       .withColumn("date_to", lit(None).cast("timestamp")))
```

- Surrogate kljuÄ dobiva stabilan redoslijed (sortirano po datumima).

#### 3.5 UNKNOWN red

```python
unknown = spark.createDataFrame([(0,1,datetime.utcnow(),None,None,None,0)], schema=dim.schema)
final_df = unknown.unionByName(dim)
```

- `incident_dates_tk = 0`, sve NULL osim trajanja =Â 0.

---

### 4.â€¯Pisanje u DWH

```python
final_df.write.jdbc(url, "incident_datesdim", mode="overwrite", properties=props)
```

- Tablica se overrida pri svakom pokretanju.

---

## ğŸ“Š OÄekivani rezultat

```text
INCIDENT_DATES_DIM redaka: â‰ˆÂ 3â€¯605   # 3â€¯604 stvarnih + 1 UNKNOWN
```

---

## ğŸ“ Napomene i bestâ€‘practice

1. **Fallback duration** â€“ raÄunanje `datediff * 24` pretpostavlja da su datumi ukljuÄivi i da nema vremenske zone; za preciznije trajanje koristi `unix_timestamp()`.
2. Ako Ä‡e se datumi aÅ¾urirati (SCDâ€‘2) moraÅ¡:
   - zatvoriti stari red (`date_to = NOW()`)
   - unijeti novi red s (`version += 1`).
3. ImaÅ¡ `surrogate` i `natural` kljuÄ â†’ moÅ¾eÅ¡ provjeriti povijesnu promjenu duljine incidenta.

---

**Autor**: Data Engineering pomoÄ‡nik Â· lipanjÂ 2025.

