# ğŸ§© Spark ETL â€“ Kreiranje `State_DIM` dimenzijske tablice

## ğŸ¯ Cilj  
Kreirati **dimenzijsku tablicu** `state_dim` na razini *county* (`country_name`).  
Tablica dobiva:

| Stupac            | Opis                                          |
|-------------------|-----------------------------------------------|
| `state_tk`        | Surrogate kljuÄ (1Â â€¦Â n)                       |
| `version`         | SCD verzija (zasad 1)                         |
| `date_from`       | Datum poÄetka valjanosti reda                 |
| `date_to`         | Datum kraja valjanosti (NULLÂ = aktivan)       |
| `state_name`      | Naziv savezne drÅ¾ave (VELIKA slova)           |
| `country_name`    | Naziv countyâ€‘ja (prirodni kljuÄ)              |

---

## ğŸš€ 1. SparkSession
```python
spark = (SparkSession.builder
         .appName("US_DISASTER_SCHEMA")
         .config("spark.sql.shuffle.partitions", "4")
         .getOrCreate())
```
Manji broj particija smanjuje overhead za dataset od ~60â€¯k redova.

---

## ğŸ—„ï¸ 2. Extract
### 2.1 Iz OLTP baze
```python
db_states = spark.read.jdbc(... '"State"' ...) \
           .select(upper(trim(col("name"))).alias("state_name"),
                   upper(trim(col("country_name"))).alias("country_name"))
```
### 2.2 Iz CSVâ€‘a (20Â %)
```python
csv_states = spark.read.csv(...).select(
                 upper(trim(col("state"))).alias("state_name"),
                 upper(trim(col("country_name"))).alias("country_name"))
```

---

## ğŸ”— 3. Union & dedup
```python
all_counties = (db_states.unionByName(csv_states)
                         .filter(col("country_name").isNotNull())
                         .dropDuplicates(["country_name"]))
```
Po jednom redu za svaki county.

---

## ğŸ”¢ 4. Surrogate kljuÄ + SCD
```python
w = Window.orderBy("country_name")
dim = (all_counties
       .withColumn("state_tk", row_number().over(w))
       .withColumn("version", lit(1))
       .withColumn("date_from", current_timestamp())
       .withColumn("date_to", lit(None).cast("timestamp")))
```

---

## â“ 5. UNKNOWN red
```python
unknown = spark.createDataFrame(
    [(0,1,datetime.utcnow(),None,"UNKNOWN","UNKNOWN")],
    schema=dim.schema)
final_df = unknown.unionByName(dim)
```

---

## ğŸ’¾ 6. Spremanje
```python
final_df.write.jdbc(url, "state_dim", mode="overwrite", properties=props)
```

Rezultat: **â‰ˆ 3â€¯316** redova (3â€¯315 countyâ€‘ja + UNKNOWN).

---

*Autor: Data Engineering pomoÄ‡nik Â· lipanjÂ 2025.*
